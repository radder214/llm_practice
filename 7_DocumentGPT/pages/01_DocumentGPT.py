import streamlit as st
# [as-is]
from langchain.document_loaders import UnstructuredFileLoader
# [to-be]
from langchain_unstructured     import UnstructuredLoader
from langchain.text_splitter    import CharacterTextSplitter
from langchain_openai           import OpenAIEmbeddings
from langchain.vectorstores     import Chroma, FAISS
from langchain.embeddings       import CacheBackedEmbeddings
from langchain.storage          import LocalFileStore

st.set_page_config(page_title="Document GPT", page_icon="ğŸ“–")

# @st.cache_data ==> decorator
    # ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ ë“¤ì–´ì˜¬ ë•Œ ë§ˆë‹¤ load, split, embedding ë“±ì„ í•  ìˆ˜ëŠ” ì—†ë‹¤.
    # ë„˜ê²¨ë°›ì€ íŒŒì¼ì´ ë™ì¼í•˜ë‹¤ë©´ í•´ë‹¹ í•¨ìˆ˜ë¥¼ ì¬ì‹¤í–‰í•˜ì§€ ì•ŠëŠ”ë‹¤.
    # ì¬ì‹¤í–‰í•˜ëŠ” ëŒ€ì‹ ì— ê¸°ì¡´ì— ë°˜í™˜í–ˆë˜ ê°’ì„ ë‹¤ì‹œ ë°˜í™˜í•œë‹¤.
# @st.cache_data(show_spinner="Embedding file...") ==> ì˜¤ë¥˜ ë°œìƒí•´ì„œ ìš°ì„  st.cache_resource ì„ì‹œë¡œ ì‚¬ìš© [24.12.01]
@st.cache_resource(show_spinner="Embedding file...")
def embed_file(file):
    # 2.
    # upload ëœ íŒŒì¼ ì €ì¥ ==> UnstructuredFileLoader ì—ê²Œ íŒŒì¼ ìœ„ì¹˜ë¥¼ ë„˜ê²¨ì£¼ê¸° ìœ„í•´
    file_content = file.read()
    file_path    = f"./cache/files/{file.name}" # íŒŒì¼ ì €ì¥ ê²½ë¡œ

    # 3. file_content ë‚´ìš©ì„ file_path ì— ì €ì¥
        # open(file_path, ...) ==> file_pathì— ìˆëŠ” íŒŒì¼ì„ ì—´ì–´ë¼
        # wb = íŒŒì¼ì„ binaryë¡œ write
    with open(file_path, mode="wb") as uploaded_file:
        uploaded_file.write(file_content)

    # 4. embedding í•œ ê²ƒì„ ì €ì¥í•  ê²½ë¡œ For Cache
    cache_dir = LocalFileStore(f"./cache/embeddings/{file.name}")
    
    # 5. text splitter ì„¤ì •
    splitter = CharacterTextSplitter.from_tiktoken_encoder(
        separator     = "\n",
        chunk_size    = 600,
        chunk_overlap = 100
    )

    # 6. íŒŒì¼ load and split
    # [as-is]
    # loader = UnstructuredFileLoader(file_path)
    # [to-be]
    loader = UnstructuredLoader(file_path)
    docs = loader.load_and_split(text_splitter=splitter)

    # 7. embedding
    embedding = OpenAIEmbeddings()
    cached_embedding = CacheBackedEmbeddings.from_bytes_store(
        underlying_embeddings    = embedding,
        document_embedding_cache = cache_dir
    )
    # Chromaë¡œ í•˜ë‹ˆê¹Œ í•´ë‹¹ ë‹¨ê³„ì—ì„œ Errorê°€ ë°œìƒí•´ì„œ FAISSë¡œ ë³€ê²½
    vectorStore = FAISS.from_documents(
        documents = docs,
        embedding = cached_embedding
    )

    # 8. vector Storeì—ì„œ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
    retriever = vectorStore.as_retriever(
        search_type="similarity",   # ìœ ì‚¬ë„ ê²€ìƒ‰ ë°©ì‹
        search_kwargs={"k": 6}      # ê²€ìƒ‰ ê´€ë ¨ ì¶”ê°€ íŒŒë¼ë¯¸í„°
                                        # "k": 6 ==> 6ê°œì˜ ê²€ìƒ‰ê²°ê³¼ ë°˜í™˜
    )
    return retriever

# ìƒì„±ëœ ë©”ì‹œì§€ë¥¼ í™”ë©´ì— ë¿Œë¦°ë‹¤ & st.session_state.messagesì— ì €ì¥
def send_message(message, role, save=True):
    with st.chat_message(role):
        st.markdown(message)
    if save:
        st.session_state.messages.append({
            "message" : message,
            "role"    : role
        })

# st.session_state.messagesì— ë‹´ê²¨ìˆëŠ” ì±„íŒ… ê¸°ë¡ì„ í™”ë©´ì— ë¿Œë¦°ë‹¤.
def paint_history():
    for message in st.session_state.messages:
        send_message(message["message"], message["role"], False)

st.title("Document GPT")

st.markdown("""
    ## Welcome!
    ##### Use this chatbot to ask questions to an AI about your files!
    ##### Upload your files on the sidebar.
""")

# 1.
# ì‚¬ìš©ìê°€ ë³¸ì¸ì˜ íŒŒì¼ upload
with st.sidebar:
    file = st.file_uploader(
        label= "Upload a .txt, .pdf, .docx file",
        type = ["txt", "pdf", "docx"]
    )

if file:
    # 1-1. ì§ˆë¬¸í•˜ê³  ëŒ€ë‹µì„ ë°›ëŠ”ë‹¤.
    retriever = embed_file(file)
    send_message("I'm ready! Ask away!", "ai", False)
    paint_history()
    
    message = st.chat_input("Ask anything about your file")
    if message:
        send_message(message    , "human")
        send_message("ai_answer", "ai")
else :
    # 1. ê¸°ì¡´ì— upload í•œ íŒŒì¼ì„ ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•Šê³  ë‹¤ë¥¸ íŒŒì¼ì„ upload í›„ ì‚¬ìš©í•˜ê³  ì‹¶ì„ ë•Œ
    # 2. í™”ë©´ì— ì²˜ìŒ ë“¤ì–´ ì™”ì„ ë•Œì—ë„ ì•„ë˜ ì½”ë“œê°€ ì‹¤í–‰ëœë‹¤.(file ë³€ìˆ˜ì˜ ê°’ì´ ì—†ìœ¼ë¯€ë¡œ)
    st.session_state.messages = [] # session_state ì´ˆê¸°í™”